{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion mnist keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_647wvfN-au",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import keras \n",
        "from sklearn.preprocessing import OneHotEncoder as ONE\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJGY53THOAkd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = data.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Fss22p0OV-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#scaling\n",
        "train_images = train_images/255\n",
        "test_images = test_images/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdNNTNKGfQfx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = train_images.reshape(train_images.shape[0],train_images.shape[1],train_images.shape[2],1)\n",
        "test_images = test_images.reshape(test_images.shape[0],test_images.shape[1],test_images.shape[2],1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOeC7pTMg0F7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels.resize(len(train_labels),1)\n",
        "test_labels.resize(len(test_labels),1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mA3VvHNyr5d",
        "colab_type": "code",
        "outputId": "3e38dc62-e09b-471e-d7c3-e4d1eb2a031b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "#one hot encoding \n",
        "ONE = ONE()\n",
        "Y_train = ONE.fit_transform(train_labels)\n",
        "Y_train = Y_train.toarray()\n",
        "Y_test = ONE.fit_transform(test_labels)\n",
        "Y_test = Y_test.toarray()\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dulf-Vm4iMJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datagen = ImageDataGenerator(featurewise_center=True,featurewise_std_normalization=True,rotation_range=20,width_shift_range=0.2,height_shift_range=0.2,horizontal_flip=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5Vnp5ygxicZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#initializing callbacks\n",
        "ES = EarlyStopping(monitor='val_loss',mode='auto',patience=2,min_delta=.03)\n",
        "LR = ReduceLROnPlateau(monitor='val_loss',mode='auto',min_lr=.001)\n",
        "MC = ModelCheckpoint(filepath='best_model.hdf5',monitor='val_loss',save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6y3a9T8ZH4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Model 1 without batch normalization and using mini-batch grad descent,data_augmentation\n",
        "model1 = keras.models.Sequential()\n",
        "\n",
        "model1.add(keras.layers.Conv2D(32, (3, 3), padding=\"same\", activation='relu',input_shape=[28, 28, 1]))\n",
        "model1.add(keras.layers.MaxPool2D((2,2)))\n",
        "\n",
        "model1.add(keras.layers.Conv2D(64, (3, 3),activation='relu'))\n",
        "model1.add(keras.layers.MaxPool2D((2,2)))\n",
        "\n",
        "model1.add(keras.layers.Flatten())\n",
        "model1.add(keras.layers.Dense(1024, activation='relu'))\n",
        "\n",
        "model1.add(keras.layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfX855jscjUH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.compile(keras.optimizers.Adam(1e-4),loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DoyCwAFGcojv",
        "colab_type": "code",
        "outputId": "c0afe60c-3a88-4269-9c1e-e4a7c8b48729",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "#model1.fit(train_images,Y_train, validation_split=.1, epochs=10, batch_size=64,callbacks=[ES,LR])\n",
        "X_train,X_test,y_train,y_test = tts(train_images,Y_train, test_size=.1)\n",
        "model1.fit_generator(datagen.flow(X_train, y_train, batch_size=100),epochs=10,steps_per_epoch=600,validation_data=(X_test,y_test))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n",
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:724: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "600/600 [==============================] - 112s 187ms/step - loss: 1.1214 - acc: 0.6053 - val_loss: 0.7427 - val_acc: 0.7193\n",
            "Epoch 2/10\n",
            "600/600 [==============================] - 109s 182ms/step - loss: 0.7868 - acc: 0.7108 - val_loss: 0.7639 - val_acc: 0.7227\n",
            "Epoch 3/10\n",
            "600/600 [==============================] - 110s 183ms/step - loss: 0.7225 - acc: 0.7323 - val_loss: 0.7069 - val_acc: 0.7380\n",
            "Epoch 4/10\n",
            "600/600 [==============================] - 110s 183ms/step - loss: 0.6819 - acc: 0.7473 - val_loss: 0.6538 - val_acc: 0.7572\n",
            "Epoch 5/10\n",
            "600/600 [==============================] - 110s 183ms/step - loss: 0.6468 - acc: 0.7601 - val_loss: 0.6024 - val_acc: 0.7692\n",
            "Epoch 6/10\n",
            "600/600 [==============================] - 110s 183ms/step - loss: 0.6207 - acc: 0.7707 - val_loss: 0.5864 - val_acc: 0.7808\n",
            "Epoch 7/10\n",
            "600/600 [==============================] - 111s 185ms/step - loss: 0.5990 - acc: 0.7781 - val_loss: 0.5242 - val_acc: 0.8060\n",
            "Epoch 8/10\n",
            "600/600 [==============================] - 110s 184ms/step - loss: 0.5820 - acc: 0.7862 - val_loss: 0.5302 - val_acc: 0.7997\n",
            "Epoch 9/10\n",
            "600/600 [==============================] - 110s 184ms/step - loss: 0.5633 - acc: 0.7931 - val_loss: 0.5160 - val_acc: 0.8102\n",
            "Epoch 10/10\n",
            "600/600 [==============================] - 111s 185ms/step - loss: 0.5474 - acc: 0.7988 - val_loss: 0.4948 - val_acc: 0.8203\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb77ac50908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVBU-KQfghdx",
        "colab_type": "code",
        "outputId": "c7e9856e-6353-4dcb-ccf8-ec81b6ec23ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "Evaluation1 = model1.evaluate(test_images,Y_test,batch_size=100)\n",
        "print('Loss on augmented data without batch normalization, dropout and early-stopping:')\n",
        "print('Test_loss:',Evaluation[0])\n",
        "print('Test_accuracy:',Evaluation[1])"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 4s 386us/step\n",
            "[0.5052466577291489, 0.8216999995708466]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuXYgutagxy6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#with batch normalization and dropout\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Conv2D(32, (3, 3), padding=\"same\", input_shape=[28, 28, 1]))\n",
        "model.add(keras.layers.BatchNormalization(momentum=.9,epsilon=.001))\n",
        "model.add(keras.layers.Activation('relu'))\n",
        "model.add(keras.layers.MaxPool2D((2,2)))\n",
        "model.add(keras.layers.Dropout(0.2))\n",
        "\n",
        "model.add(keras.layers.Conv2D(64, (3, 3)))\n",
        "model.add(keras.layers.BatchNormalization(momentum=.9,epsilon=.001))\n",
        "model.add(keras.layers.Activation('relu'))\n",
        "model.add(keras.layers.MaxPool2D((2,2)))\n",
        "model.add(keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(128, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95riEbJ8ewf3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "82bfe99c-9cfd-4ec6-e89d-6718adaa9481"
      },
      "source": [
        "#With batch normalization and dropout,data augmentation\n",
        "model.compile(keras.optimizers.Adam(1e-4),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "#model.fit(train_images,Y_train, validation_split=.1, epochs=10, batch_size=100)\n",
        "\n",
        "model.fit_generator(datagen.flow(X_train, y_train, batch_size=100),epochs=15,steps_per_epoch=600,validation_data=(X_test,y_test),callbacks=[ES,LR,MC])"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n",
            "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:724: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "600/600 [==============================] - 137s 229ms/step - loss: 1.7429 - acc: 0.3633 - val_loss: 1.0055 - val_acc: 0.6548\n",
            "Epoch 2/15\n",
            "600/600 [==============================] - 134s 224ms/step - loss: 1.2485 - acc: 0.5423 - val_loss: 0.8317 - val_acc: 0.7107\n",
            "Epoch 3/15\n",
            "600/600 [==============================] - 135s 224ms/step - loss: 1.0865 - acc: 0.6014 - val_loss: 0.7604 - val_acc: 0.7325\n",
            "Epoch 4/15\n",
            "600/600 [==============================] - 135s 224ms/step - loss: 0.9986 - acc: 0.6316 - val_loss: 0.7137 - val_acc: 0.7453\n",
            "Epoch 5/15\n",
            "600/600 [==============================] - 135s 224ms/step - loss: 0.9431 - acc: 0.6544 - val_loss: 0.6710 - val_acc: 0.7550\n",
            "Epoch 6/15\n",
            "600/600 [==============================] - 134s 224ms/step - loss: 0.8981 - acc: 0.6688 - val_loss: 0.6526 - val_acc: 0.7577\n",
            "Epoch 7/15\n",
            "600/600 [==============================] - 135s 225ms/step - loss: 0.8659 - acc: 0.6811 - val_loss: 0.6677 - val_acc: 0.7535\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb77a88f668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq4NtY3yfKT7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "80fe3fc2-3c21-446a-d1d2-fd34883bae48"
      },
      "source": [
        "#Evaluation of accuracy\n",
        "Evaluation = model.evaluate(test_images,Y_test,batch_size=100)\n",
        "print('Loss on augmented data without batch normalization, dropout and early-stopping:')\n",
        "print('Test_loss:',Evaluation[0])\n",
        "print('Test_accuracy:',Evaluation[1])\n"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 7s 663us/step\n",
            "Loss on augmented data without batch normalization, dropout and early-stopping:\n",
            "Test_loss: 0.668391487300396\n",
            "Test_accuracy: 0.7508000022172928\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3UnHPni26wU",
        "colab_type": "code",
        "outputId": "004898e4-8009-49f3-c8d4-c857f8df067f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        }
      },
      "source": [
        "# Classification report on both the models\n",
        "from sklearn.preprocessing import OneHotEncoder as ON\n",
        "\n",
        "Y_pred = model.predict_proba(test_images)\n",
        "Y_pred1 = model1.predict_proba(test_images)\n",
        "\n",
        "classes = np.argmax(Y_pred,axis=1).reshape(len(Y_pred),1)\n",
        "classes1 = np.argmax(Y_pred1,axis=1).reshape(len(Y_pred),1)\n",
        "\n",
        "ON = ON()\n",
        "classes = ON.fit_transform(classes).toarray() \n",
        "classes1 = ON.fit_transform(classes1).toarray() \n",
        "\n",
        "print('Classification report on augmented data with batch_norm, early_stopping and dropout')\n",
        "print(classification_report(Y_test,classes))\n",
        "\n",
        "\n",
        "print('Classification report on augmented data without batch_norm, early_stopping and dropout')\n",
        "print(classification_report(Y_test,classes1))\n"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification report on augmented data with batch_norm, early_stopping and dropout\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.77      0.76      1000\n",
            "           1       0.93      0.96      0.95      1000\n",
            "           2       0.48      0.83      0.61      1000\n",
            "           3       0.72      0.82      0.77      1000\n",
            "           4       0.67      0.51      0.58      1000\n",
            "           5       0.77      0.94      0.85      1000\n",
            "           6       0.39      0.10      0.16      1000\n",
            "           7       0.83      0.80      0.81      1000\n",
            "           8       0.93      0.92      0.92      1000\n",
            "           9       0.94      0.86      0.90      1000\n",
            "\n",
            "   micro avg       0.75      0.75      0.75     10000\n",
            "   macro avg       0.74      0.75      0.73     10000\n",
            "weighted avg       0.74      0.75      0.73     10000\n",
            " samples avg       0.75      0.75      0.75     10000\n",
            "\n",
            "Classification report on augmented data without batch_norm, early_stopping and dropout\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.81      0.80      1000\n",
            "           1       0.97      0.97      0.97      1000\n",
            "           2       0.68      0.82      0.74      1000\n",
            "           3       0.81      0.87      0.84      1000\n",
            "           4       0.77      0.61      0.68      1000\n",
            "           5       0.81      0.98      0.88      1000\n",
            "           6       0.60      0.54      0.57      1000\n",
            "           7       0.88      0.83      0.86      1000\n",
            "           8       0.95      0.95      0.95      1000\n",
            "           9       0.97      0.84      0.90      1000\n",
            "\n",
            "   micro avg       0.82      0.82      0.82     10000\n",
            "   macro avg       0.82      0.82      0.82     10000\n",
            "weighted avg       0.82      0.82      0.82     10000\n",
            " samples avg       0.82      0.82      0.82     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Al-EOVuX9ruF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classification_report(Y_test,classes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVnSQc7N9wml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kQG7LlW9ytI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}